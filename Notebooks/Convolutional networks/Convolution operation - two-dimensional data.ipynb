{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI6oVy6pMr23"
      },
      "source": [
        "##### AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Programu Operacyjnego Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1lES9XmcTvn"
      },
      "source": [
        "# Uczenie głębokie\n",
        "\n",
        "Jacek Rumiński, Politechnika Gdańska, Wydział ETI, Katedra Inżynierii Biomedycznej\n",
        "\n",
        "**Wykład 2:** Sieci splotowe\n",
        "\n",
        "**Przykład (2):** Operacja splotu - dane dwuwymiarowe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68i1TdSOj7QS"
      },
      "source": [
        "W ramach tego notatnika zapoznajmy się z metodami dotyczącymi operacji splotu i jej zastosowania w sztucznych sieciach neuronowych na przykładzie danych dwuwymiarowych.\n",
        "\n",
        "\n",
        "Wskażmy pakiety, z jakich będziemy korzystać:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrCMqw7lM2Lo",
        "outputId": "a1e80d9b-ebbb-48b4-ac0b-884e9ff3a07a"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6BiVL3WCAqO"
      },
      "source": [
        "Rozpatrzmy prosty przykład danych 2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1XJ2n9gjceE",
        "outputId": "ff78a78b-2f53-49b3-e133-a5888d60c8e1"
      },
      "source": [
        "img = np.array([\n",
        "                [1.,1.,1.,1.],\n",
        "                [1.,10.,1.,1.],\n",
        "                [1.,1.,1.,1.],\n",
        "                [1.,1.,1.,1.]\n",
        "              ])\n",
        "\n",
        "print(\"Data shape: \", img.shape)\n",
        "\n",
        "# Reshape to get width:4, height:4, depth:1 (No. of components per sample)\n",
        "img_with_depth = img.reshape(4,4,1)\n",
        "print(\"\\nData shape after 1st reshape: \", img_with_depth.shape)\n",
        "print(\"Data after 1st reshape: \\n\",img_with_depth)\n",
        "\n",
        "# In practice, we often work with more than one example\n",
        "# Lets reshape our example, indicating that we have one example (for now...)\n",
        "img_with_depth_and_batch = img_with_depth.reshape(1,4,4,1)\n",
        "\n",
        "print(\"\\nData shape after 2nd reshape: \", img_with_depth_and_batch.shape)\n",
        "print(\"Data after 2nd reshape: \\n\",img_with_depth_and_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data shape:  (4, 4)\n",
            "\n",
            "Data shape after 1st reshape:  (4, 4, 1)\n",
            "Data after 1st reshape: \n",
            " [[[ 1.]\n",
            "  [ 1.]\n",
            "  [ 1.]\n",
            "  [ 1.]]\n",
            "\n",
            " [[ 1.]\n",
            "  [10.]\n",
            "  [ 1.]\n",
            "  [ 1.]]\n",
            "\n",
            " [[ 1.]\n",
            "  [ 1.]\n",
            "  [ 1.]\n",
            "  [ 1.]]\n",
            "\n",
            " [[ 1.]\n",
            "  [ 1.]\n",
            "  [ 1.]\n",
            "  [ 1.]]]\n",
            "\n",
            "Data shape after 2nd reshape:  (1, 4, 4, 1)\n",
            "Data after 2nd reshape: \n",
            " [[[[ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]]\n",
            "\n",
            "  [[ 1.]\n",
            "   [10.]\n",
            "   [ 1.]\n",
            "   [ 1.]]\n",
            "\n",
            "  [[ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]]\n",
            "\n",
            "  [[ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2UzM9r6DeJV"
      },
      "source": [
        "Przeprowadzimy teraz operację splotu dla danych 2D i predefiniowanej maski splotu, analogicznie do wsześniejszego notatnika z przykładami dla danych 1D."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDGXZr8bkftD",
        "outputId": "aa412720-6d64-4a34-ab43-c192645dce70"
      },
      "source": [
        "# Data shape is: (batch_size, number of rows, number of columns, number of channels)\n",
        "\n",
        "# Weights shape should be (kernel_height, kernel_width, input_depth, number_of_filters)\n",
        "kernel_width = kernel_height = 3\n",
        "input_depth = 1\n",
        "number_of_filters = 1  # No. of outputs\n",
        "\n",
        "w_init_2D_1 = np.ones((kernel_height,kernel_width,input_depth,number_of_filters))\n",
        "\n",
        "# Normalize weights\n",
        "w_init_2D_1 /= np.sum(w_init_2D_1)\n",
        "print(\"\\nPredefined weights shape: \", w_init_2D_1.shape)\n",
        "print(\"Predefined weights: \\n\", w_init_2D_1)\n",
        "\n",
        "# Define the Conv2D layer\n",
        "layer_2D_1 = tf.keras.layers.Conv2D(number_of_filters,\n",
        "                                 kernel_size=(kernel_height, kernel_width),\n",
        "                                 strides = (1,1),\n",
        "                                 padding='valid',\n",
        "                                 activation='linear',\n",
        "                                 use_bias=False,\n",
        "                                 weights=[w_init_2D_1])\n",
        "\n",
        "# Apply Conv2D layer and print results\n",
        "x_2D_1 = layer_2D_1(img_with_depth_and_batch)\n",
        "# print(\"\\nLayer weights: \\n\", layer_2D_1.weights)\n",
        "print(\"\\nResults shape: \", x_2D_1.shape)\n",
        "print(\"Results: \\n\", x_2D_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Predefined weights shape:  (3, 3, 1, 1)\n",
            "Predefined weights: \n",
            " [[[[0.11111111]]\n",
            "\n",
            "  [[0.11111111]]\n",
            "\n",
            "  [[0.11111111]]]\n",
            "\n",
            "\n",
            " [[[0.11111111]]\n",
            "\n",
            "  [[0.11111111]]\n",
            "\n",
            "  [[0.11111111]]]\n",
            "\n",
            "\n",
            " [[[0.11111111]]\n",
            "\n",
            "  [[0.11111111]]\n",
            "\n",
            "  [[0.11111111]]]]\n",
            "\n",
            "Results shape:  (1, 2, 2, 1)\n",
            "Results: \n",
            " tf.Tensor(\n",
            "[[[[2.]\n",
            "   [2.]]\n",
            "\n",
            "  [[2.]\n",
            "   [2.]]]], shape=(1, 2, 2, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOv61Tv8QiWs"
      },
      "source": [
        "Zastanówmy się na chwilę, dlaczego otrzymaliśmy wartości równe 2?\n",
        "\n",
        "Rozpatrzmy pierwszy segment o rozmiarze 3x3 z danych wejściowych: [[1,1,1], [1,10,1], [1,1,1]]. Suma wartości to 10+8*1=18. Pomnóżmy je przez 1/9 (lub podzielmy przez 9 - suma współczynników maski) i otrzymamy 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNVraQPWEz5s"
      },
      "source": [
        "Warto zauważyć, że rozmiar przestrzenny danych wyjściowych jest mniejszy niż danych wejściowych. Podobnie jak wcześniej możemy zastosować metodę uzupełniania danych (np.  padding='same' - uzupełnij przez 0) w celu uzyskanie takich samych rozmiarów tesnorów danych.\n",
        "\n",
        "Posłużmy się jeszcze innym przykładem, zawierającym dane o głębokości 3 (np. tak jak dla danych obrazu RGB - 3 próbki reprezentujące kolor jednego piksela).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNQ0oBmYqo3F",
        "outputId": "a77d74e3-a555-4d06-c50b-75b796db7a1c"
      },
      "source": [
        "img_depth_3 = np.array([\n",
        "                      [[1., 2. ,1.],[1., 2. ,1.],[1., 2. ,1.],[1., 2. ,1.]],\n",
        "                      [[1., 2. ,1.],[10., 29. ,10.],[1., 2. ,1.],[1., 2. ,1.]],\n",
        "                      [[1., 2. ,1.],[1., 2. ,1.],[1., 2. ,1.],[1., 2. ,1.]],\n",
        "                      [[1., 2. ,1.],[1., 2. ,1.],[1., 2. ,1.],[1., 2. ,1.]]\n",
        "                      ])\n",
        "\n",
        "\n",
        "print(img_depth_3.shape)\n",
        "\n",
        "\n",
        "img_depth_3_and_batch = img_depth_3.reshape(1,4,4,3)\n",
        "print(img_depth_3_and_batch.shape)\n",
        "print(img_depth_3_and_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 4, 3)\n",
            "(1, 4, 4, 3)\n",
            "[[[[ 1.  2.  1.]\n",
            "   [ 1.  2.  1.]\n",
            "   [ 1.  2.  1.]\n",
            "   [ 1.  2.  1.]]\n",
            "\n",
            "  [[ 1.  2.  1.]\n",
            "   [10. 29. 10.]\n",
            "   [ 1.  2.  1.]\n",
            "   [ 1.  2.  1.]]\n",
            "\n",
            "  [[ 1.  2.  1.]\n",
            "   [ 1.  2.  1.]\n",
            "   [ 1.  2.  1.]\n",
            "   [ 1.  2.  1.]]\n",
            "\n",
            "  [[ 1.  2.  1.]\n",
            "   [ 1.  2.  1.]\n",
            "   [ 1.  2.  1.]\n",
            "   [ 1.  2.  1.]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrimSfW4IdpW"
      },
      "source": [
        "Zastosujmy operację Conv2D:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFgRpmJKrNfI",
        "outputId": "dea4a656-7fab-447e-cbd8-b590e781ef3c"
      },
      "source": [
        "# Data shape: (batch_size, number of rows, number of columns, number of channels)\n",
        "\n",
        "# Weights shape should be (kernel_height, kernel_width, input_depth, number_of_filters)\n",
        "kernel_width = kernel_height = 3\n",
        "input_depth = 3\n",
        "number_of_filters = 1  # No. of outputs\n",
        "\n",
        "w_init_2D_2 = np.ones((kernel_height,kernel_width,input_depth,number_of_filters))\n",
        "w_init_2D_2 /= np.sum(w_init_2D_2)\n",
        "print(\"\\nPredefined weights shape: \", w_init_2D_2.shape)\n",
        "print(\"Predefined weights: \\n\", w_init_2D_2)\n",
        "\n",
        "layer_2D_2 = tf.keras.layers.Conv2D(number_of_filters,\n",
        "                                 kernel_size=(kernel_height, kernel_width),\n",
        "                                 padding='valid',\n",
        "                                 activation='linear',\n",
        "                                 use_bias=False,\n",
        "                                 weights=[w_init_2D_2])\n",
        "\n",
        "x_2D_2 = layer_2D_2(img_depth_3_and_batch)\n",
        "# print(layer_2D_2.weights)\n",
        "print(\"\\nResults shape: \", x_2D_2.shape)\n",
        "print(\"Results: \\n\", x_2D_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Predefined weights shape:  (3, 3, 3, 1)\n",
            "Predefined weights: \n",
            " [[[[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]]\n",
            "\n",
            "\n",
            " [[[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]]\n",
            "\n",
            "\n",
            " [[[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]]]\n",
            "\n",
            "Results shape:  (1, 2, 2, 1)\n",
            "Results: \n",
            " tf.Tensor(\n",
            "[[[[3.0000002]\n",
            "   [3.0000002]]\n",
            "\n",
            "  [[3.0000002]\n",
            "   [3.0000002]]]], shape=(1, 2, 2, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScBeACg1H7Xv"
      },
      "source": [
        "Ważne: uzyskaliśmy taki sam rozmiar danych wyjściowych jak w poprzednim przykładzie pomimo tego, że głębokość danych wynosiła 3 (shape (4,4,3)), a nie 1 (input shape: (4,4,1)). Stało się tak dlatego, że operacja splotu Conv2D (a właściwie korelacji wzajemnej implementowanej w TF/PyTorch) wykorzystuje wszystkie dane wyznaczając wynik.\n",
        "\n",
        "Oczywiście możemy zastosować też taką wersję operacji splotu, żeby dla każdego komponentu (cechy, głębokości) uzyskać oddzielny wynik. Jest to możlize poprzez zastosowanie klasy DepthwiseConv2D."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBHv4bxxFvfU",
        "outputId": "a8f9227f-ea76-4cd5-fe74-a0ddb7596500"
      },
      "source": [
        "# Data shape: (batch_size, number of rows, number of columns, number of channels)\n",
        "\n",
        "# Weights shape should be (kernel_height, kernel_width, input_depth, number_of_filters)\n",
        "kernel_width = kernel_height = 3\n",
        "input_depth = 3\n",
        "number_of_filters = 1  # No. of outputs\n",
        "\n",
        "w_init_2D_3 = np.ones((kernel_height,kernel_width,input_depth,number_of_filters))\n",
        "w_init_2D_3 /= np.sum(w_init_2D_3) # Another normalization should be used\n",
        "print(\"\\nPredefined weights shape: \", w_init_2D_3.shape)\n",
        "print(\"Predefined weights: \\n\", w_init_2D_3)\n",
        "\n",
        "layer_2D_3 = tf.keras.layers.DepthwiseConv2D( # number_of_filters, <- we do not use it\n",
        "                                 kernel_size=(kernel_height, kernel_width),\n",
        "                                 padding='valid',\n",
        "                                 activation='linear',\n",
        "                                 use_bias=False,\n",
        "                                 weights=[w_init_2D_3])\n",
        "\n",
        "x_2D_3 = layer_2D_3(img_depth_3_and_batch)\n",
        "# print(layer_2D_3.weights)\n",
        "print(\"\\nResults shape: \", x_2D_3.shape)\n",
        "print(\"Results: \\n\", x_2D_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Predefined weights shape:  (3, 3, 3, 1)\n",
            "Predefined weights: \n",
            " [[[[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]]\n",
            "\n",
            "\n",
            " [[[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]]\n",
            "\n",
            "\n",
            " [[[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]\n",
            "\n",
            "  [[0.03703704]\n",
            "   [0.03703704]\n",
            "   [0.03703704]]]]\n",
            "\n",
            "Results shape:  (1, 2, 2, 3)\n",
            "Results: \n",
            " tf.Tensor(\n",
            "[[[[0.66666657 1.6666665  0.66666657]\n",
            "   [0.66666657 1.6666665  0.66666657]]\n",
            "\n",
            "  [[0.66666657 1.6666664  0.66666657]\n",
            "   [0.6666666  1.6666663  0.6666666 ]]]], shape=(1, 2, 2, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TNVM4-MSZVA"
      },
      "source": [
        "Rozmiar danych wyjściowych wynosi (1, 2, 2, 3): 3 macierze, każda o wymiarze 2x2.\n",
        "Oznacza to, że operacje splotu (jakby Conv2D) zostały zastosowane oddzielnie do każdego komponentu: pierwszy komponent (2x2) -> jeden wynik, drugi komponent(2x2) -> drugi wynik i trzeci komponent (2x2)-> trzeci wynik.\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fTaloIWTrxU"
      },
      "source": [
        "Warto teraz przedstawić istotny aspekt praktyczny: zastosowanie operacji Conv2D z maską o rozmiarze (1,1). Jeśli głębokość danych będzie równa 1, wówczas wynik operacji splotu danych wyściowych z maską (1,1) spowoduje w praktyce utworzenie kopii danych wejściowych (jeśli waga =1). Jeśli głębokość danych jest większa, np. 3, wówczas operacja Conv2D (ale nie Depthwise) przeprowadzi splot dla każdego komponentu i ZSUMUJE wynik od każdego komponentu zwracając pojedynczą wartość.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMhSlLzssC0g"
      },
      "source": [
        "Zilustrujmy operację Conv2D stosując maskę o rozmiarze (1,1):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWgwu7iiAY9-",
        "outputId": "ee4bc779-d80e-4c11-8871-f9b14236a744"
      },
      "source": [
        "# Data shape: (batch_size, number of rows, number of columns, number of channels)\n",
        "\n",
        "# Weights shape should be (kernel_height, kernel_width, input_depth, number_of_filters)\n",
        "kernel_width = kernel_height = 1\n",
        "input_depth = 3\n",
        "number_of_filters = 1  # No. of outputs\n",
        "\n",
        "w_init_2D_4 = np.ones((kernel_height,kernel_width, input_depth,number_of_filters))\n",
        "w_init_2D_4 /= np.sum(w_init_2D_4)\n",
        "print(\"\\nPredefined weights shape: \", w_init_2D_4.shape)\n",
        "print(\"Predefined weights: \\n\", w_init_2D_4)\n",
        "\n",
        "layer_2D_4 = tf.keras.layers.Conv2D(number_of_filters,\n",
        "                                 kernel_size=(kernel_height, kernel_width),\n",
        "                                 padding='valid',\n",
        "                                 activation='linear',\n",
        "                                 use_bias=False,\n",
        "                                 weights=[w_init_2D_4])\n",
        "\n",
        "x_2D_4 = layer_2D_4(img_depth_3_and_batch)\n",
        "# print(layer_2D_4.weights)\n",
        "print(\"\\nResults shape: \", x_2D_4.shape)\n",
        "print(\"Results: \\n\", x_2D_4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Predefined weights shape:  (1, 1, 3, 1)\n",
            "Predefined weights: \n",
            " [[[[0.33333333]\n",
            "   [0.33333333]\n",
            "   [0.33333333]]]]\n",
            "\n",
            "Results shape:  (1, 4, 4, 1)\n",
            "Results: \n",
            " tf.Tensor(\n",
            "[[[[ 1.3333334]\n",
            "   [ 1.3333334]\n",
            "   [ 1.3333334]\n",
            "   [ 1.3333334]]\n",
            "\n",
            "  [[ 1.3333334]\n",
            "   [16.333334 ]\n",
            "   [ 1.3333334]\n",
            "   [ 1.3333334]]\n",
            "\n",
            "  [[ 1.3333334]\n",
            "   [ 1.3333334]\n",
            "   [ 1.3333334]\n",
            "   [ 1.3333334]]\n",
            "\n",
            "  [[ 1.3333334]\n",
            "   [ 1.3333334]\n",
            "   [ 1.3333334]\n",
            "   [ 1.3333334]]]], shape=(1, 4, 4, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX-IZ9PhBJL1"
      },
      "source": [
        "Ponieważ wagi maski są równe 1/3, dlatego otrzymaliśmy wartość średnią np.: ( (1*1/3) + (2*1/3) + (1*1/3)) = 4/3 = 1.333(3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaKDw2jdGLO3"
      },
      "source": [
        "**Wnioski:**\n",
        "\n",
        "Dla danych 2D o głębokości > 1 możemy przybliżać operację Conv2D poprzez separację dwóch działań:\n",
        "-  Conv2d z maską (1x1) w celu realizacji operacji splotu po komponentach (redukujemy głębokość do 1 - \"spłaszczamy\" dane)\n",
        "-  Conv2d z maska przestrzenną dla danych wejsciowych o głębokości 1 (wynik poprzedniego działania).\n",
        "\n",
        "Zauważmy, że dla danych zastosowanych w powyższych przykładach rozmiar tensorów predefiniowanych wag wynosił:\n",
        "\n",
        "1) Conv2D dla maski (3,3) i danych o głębokości 3 (1,4,4,3) -> tensor predefiniowanych wag miał rozmiar (3, 3, 3, 1) - 27 parameterów.\n",
        "\n",
        "2) separując operację Conv2d na:\n",
        "* Conv2D z maską (1,1)  i danych o głębokości 3 (1,4,4,3)  -> tensor predefiniowanych wag ma rozmiar (1, 1, 3, 1) - 3 parametery) i dalej\n",
        "* Conv2D z maską (3,3) dla \"płaskich danych\" (1,4,4,1) -> tensor predefiniowanych wag ma rozmiar (3, 3, 1, 1) - 9 parameterów)\n",
        "\n",
        "Czyli w drugiej konfiguracji mamy znacznie mniej parametrów: 3+(3*3)=12 (zamiast 27).\n",
        "\n",
        "Dlatego w niektórych modelach stosuje się blok dwóch operacji (Conv2D z (1,1) i Conv2D z maską przestrzenną) zamiast tradycyjnej operacji splotu Conv2D. W ten sposób uzyskuje się mniejszą liczbę parametrów do uczenia czy wykorzystania (mniej pamięci, potencjalnie krótszy trening i inferencja)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c24jtSaa3AwT"
      },
      "source": [
        "W praktyce stosuje się jeszcze szereg innych odmian operacji powiażanych ze splotem, m.in.:\n",
        "\n",
        "- LocallyConnected2D - operacja splotu bez współdzielenia wag - różne wagi (filtry) są użyte do różnych regionów (segmentów) danych wejsciowych,\n",
        "- Conv2DTranspose - tzw. transposed convolution, operacja estymująca odwrotną operację splotu (w stylu rozplotu - ang. deconvolution). Nie jest jednak tożsama z rozplotem.\n",
        "- Conv3D (i innej jak wyżej dla dla 3D) - podobne operacje jak dla 1D czy 2D, ale zdefiniowane dla danych trójwymiarowych (plus dane głębokości).\n",
        "\n",
        "Zachęcam do lektury powiazanych artykułów:\n",
        "- https://arxiv.org/abs/1603.07285v1\n",
        "- https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf\n",
        "\n",
        "Zilustrujmy jak działa operacja zaimplementowana przez LocallyConnected2D:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92VAqGlb6aZG",
        "outputId": "2319860a-126a-4b2c-d71e-8dac8b280f6b"
      },
      "source": [
        "print(\"\\nInput shape: \", img_with_depth_and_batch.shape)\n",
        "print(\"Input: \\n\", img_with_depth_and_batch)\n",
        "\n",
        "# Weights shape should be (kernel_height, kernel_width, input_depth, number_of_filters)\n",
        "kernel_width = kernel_height = 1\n",
        "input_depth = 1\n",
        "number_of_filters = 1  # No. of outputs\n",
        "\n",
        "# LocallyConnected2D - weights are not shared, so if rows = 4, cols = 4\n",
        "# then we have 4 x 4 x kernel_size filters, so shape\n",
        "# (no_of_conv_positions, input_depth * number_of_coef, number_of_filters)\n",
        "# We have 4 x 4 elements so for kernel (1,1) we have 16 conv. positions (16,,)\n",
        "# For each position we have one coefficient. The input depth is 1, so\n",
        "# input_depth * number_of_coef = 1, number_of_filters = 1, so: (16,1,1)\n",
        "# w_init_2D_5 = np.ones((kernel_width*kernel_height,input_depth,number_of_filters))\n",
        "\n",
        "# w_init_2D_5 = np.ones((16,1,1))\n",
        "w_init_2D_5 = np.random.rand(16,1,1)\n",
        "\n",
        "# Normalize weights\n",
        "# w_init_2D_5 /= np.sum(w_init_2D_5)\n",
        "print(\"\\nPredefined weights shape: \", w_init_2D_5.shape)\n",
        "print(\"Predefined weights: \\n\", w_init_2D_5)\n",
        "\n",
        "# Define the Conv2D layer\n",
        "layer_2D_5 = tf.keras.layers.LocallyConnected2D(number_of_filters,\n",
        "                                 kernel_size=(kernel_height, kernel_width),\n",
        "                                 strides = (1,1),\n",
        "                                 padding='valid',\n",
        "                                 activation='linear',\n",
        "                                 use_bias=False,\n",
        "                                 weights=[w_init_2D_5])\n",
        "\n",
        "# Apply Conv2D layer and print results\n",
        "x_2D_5 = layer_2D_5(img_with_depth_and_batch)\n",
        "# print(\"\\nLayer weights: \\n\", layer_2D_5.weights)\n",
        "print(\"\\nResults shape: \", x_2D_5.shape)\n",
        "print(\"Results: \\n\", x_2D_5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input shape:  (1, 4, 4, 1)\n",
            "Input: \n",
            " [[[[ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]]\n",
            "\n",
            "  [[ 1.]\n",
            "   [10.]\n",
            "   [ 1.]\n",
            "   [ 1.]]\n",
            "\n",
            "  [[ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]]\n",
            "\n",
            "  [[ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]\n",
            "   [ 1.]]]]\n",
            "\n",
            "Predefined weights shape:  (16, 1, 1)\n",
            "Predefined weights: \n",
            " [[[0.58872979]]\n",
            "\n",
            " [[0.71151451]]\n",
            "\n",
            " [[0.14795233]]\n",
            "\n",
            " [[0.04946201]]\n",
            "\n",
            " [[0.5054785 ]]\n",
            "\n",
            " [[0.06850583]]\n",
            "\n",
            " [[0.58798162]]\n",
            "\n",
            " [[0.74222131]]\n",
            "\n",
            " [[0.27405525]]\n",
            "\n",
            " [[0.3227287 ]]\n",
            "\n",
            " [[0.00293675]]\n",
            "\n",
            " [[0.77334249]]\n",
            "\n",
            " [[0.59559146]]\n",
            "\n",
            " [[0.35776121]]\n",
            "\n",
            " [[0.37155538]]\n",
            "\n",
            " [[0.60529598]]]\n",
            "\n",
            "Results shape:  (1, 4, 4, 1)\n",
            "Results: \n",
            " tf.Tensor(\n",
            "[[[[0.5887298 ]\n",
            "   [0.71151453]\n",
            "   [0.14795233]\n",
            "   [0.04946201]]\n",
            "\n",
            "  [[0.5054785 ]\n",
            "   [0.6850583 ]\n",
            "   [0.58798164]\n",
            "   [0.7422213 ]]\n",
            "\n",
            "  [[0.27405524]\n",
            "   [0.3227287 ]\n",
            "   [0.00293675]\n",
            "   [0.7733425 ]]\n",
            "\n",
            "  [[0.5955915 ]\n",
            "   [0.3577612 ]\n",
            "   [0.3715554 ]\n",
            "   [0.60529596]]]], shape=(1, 4, 4, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxn7p3urtYGX"
      },
      "source": [
        "Następnie zapoznajmy się z przykładem działania operacji zaimplementowanej przez Conv2DTranspose:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAXKQfusNla-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d34309c-9f1b-4cf4-ea95-a08a47eea64e"
      },
      "source": [
        "\n",
        "print(\"\\nInput shape: \", x_2D_1.shape)\n",
        "print(\"Input: \\n\", x_2D_1)\n",
        "\n",
        "# Data shape is: (batch_size, number of rows, number of columns, number of channels)\n",
        "\n",
        "# Weights shape should be (kernel_height, kernel_width, input_depth, number_of_filters)\n",
        "kernel_width = kernel_height = 3\n",
        "input_depth = 1\n",
        "number_of_filters = 1\n",
        "\n",
        "w_init_2D_6 = np.ones((kernel_height,kernel_width, input_depth,number_of_filters))\n",
        "\n",
        "# Normalize weights\n",
        "# w_init_2D_6 /= np.sum(w_init_2D_6)\n",
        "print(\"\\nPredefined weights shape: \", w_init_2D_6.shape)\n",
        "print(\"Predefined weights: \\n\", w_init_2D_6)\n",
        "\n",
        "# Define the Conv2D layer\n",
        "layer_2D_6 = tf.keras.layers.Conv2DTranspose(number_of_filters,\n",
        "                                 kernel_size=(kernel_height, kernel_width),\n",
        "                                 strides = (1,1),\n",
        "                                 padding='valid',\n",
        "                                 activation='linear',\n",
        "                                 use_bias=False,\n",
        "                                 weights=[w_init_2D_6])\n",
        "\n",
        "# Apply Conv2D layer and print results\n",
        "x_2D_6 = layer_2D_6(x_2D_1)\n",
        "# print(\"\\nLayer weights: \\n\", layer_2D_1.weights)\n",
        "print(\"\\nResults shape: \", x_2D_6.shape)\n",
        "print(\"Results: \\n\", x_2D_6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Results shape:  (1, 2, 2, 1)\n",
            "Results: \n",
            " tf.Tensor(\n",
            "[[[[2.]\n",
            "   [2.]]\n",
            "\n",
            "  [[2.]\n",
            "   [2.]]]], shape=(1, 2, 2, 1), dtype=float32)\n",
            "\n",
            "Predefined weights shape:  (3, 3, 1, 1)\n",
            "Predefined weights: \n",
            " [[[[1.]]\n",
            "\n",
            "  [[1.]]\n",
            "\n",
            "  [[1.]]]\n",
            "\n",
            "\n",
            " [[[1.]]\n",
            "\n",
            "  [[1.]]\n",
            "\n",
            "  [[1.]]]\n",
            "\n",
            "\n",
            " [[[1.]]\n",
            "\n",
            "  [[1.]]\n",
            "\n",
            "  [[1.]]]]\n",
            "\n",
            "Results shape:  (1, 4, 4, 1)\n",
            "Results: \n",
            " tf.Tensor(\n",
            "[[[[2.]\n",
            "   [4.]\n",
            "   [4.]\n",
            "   [2.]]\n",
            "\n",
            "  [[4.]\n",
            "   [8.]\n",
            "   [8.]\n",
            "   [4.]]\n",
            "\n",
            "  [[4.]\n",
            "   [8.]\n",
            "   [8.]\n",
            "   [4.]]\n",
            "\n",
            "  [[2.]\n",
            "   [4.]\n",
            "   [4.]\n",
            "   [2.]]]], shape=(1, 4, 4, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNRqK09-NuDn"
      },
      "source": [
        "Do tej pory stosowaliśmy operacje, dla których wartości maski splotu były predefiniowane. Najwyższy czas na wprowadzenie procesu uczenia wag w modelach splotowych. Tym zajmiemy się w kolejnej części.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7jy80J7ciLH"
      },
      "source": [
        "<center>\n",
        "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n",
        "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
        "    </center>"
      ]
    }
  ]
}