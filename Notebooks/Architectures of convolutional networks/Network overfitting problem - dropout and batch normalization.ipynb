{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rze6EnG6fTik"
      },
      "source": [
        "##### AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Programu Operacyjnego Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "OuaA8rFCfXTP",
        "outputId": "4027cb37-7412-437b-ad7a-f116671c1db0"
      },
      "source": [
        "#@title\n",
        "%%html\n",
        "<iframe src=\"https://www.polskacyfrowa.gov.pl/media/48246/FE_POPC_poziom_pl-1_rgb.jpg\" width=\"800\"></iframe>\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe src=\"https://www.polskacyfrowa.gov.pl/media/48246/FE_POPC_poziom_pl-1_rgb.jpg\" width=\"800\"></iframe>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6hP8DZKln80"
      },
      "source": [
        "# Uczenie głębokie\n",
        "\n",
        "Jacek Rumiński, Politechnika Gdańska, Wydział ETI, Katedra Inżynierii Biomedycznej\n",
        "\n",
        "**Wykład 4:** Architektury sieci splotowych\n",
        "\n",
        "**Przykład (1):** Problem przeuczenia sieci - \"dropout\" i \"batch normalization\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yfD5HsRfosc"
      },
      "source": [
        "W ramach tego notatnika zapoznajmy się z aspektami regularyzacji modelu/procesu uczenia z wykorzystaniem operacji logicznej redukcji neuronów (ang. (neuron) dropout) oraz standardyzacji porcji danych (ang. batch normalization).\n",
        "\n",
        "Wskażmy pakiety, z jakich będziemy korzystać:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL1UM5173hO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d196c2-f79a-4be4-da85-281e45a4b732"
      },
      "source": [
        "import numpy as np\n",
        "import datetime, os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import seaborn as sns; sns.set_theme()\n",
        "from matplotlib.colors import ListedColormap\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "font = {'family' : 'DejaVu Sans',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 22}\n",
        "\n",
        "# You can try to change your Google Colab environment to GPU\n",
        "print(tf.__version__)\n",
        "\n",
        "# You can always check which packages are installed using:\n",
        "# !pip list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGFHaMk0HN9G",
        "outputId": "d2ad4a7d-102c-43fd-a7b5-713e1d730393"
      },
      "source": [
        "# Check if you have GPU resources (Runtime / Change runtime type -> GPU)\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 25 13:15:51 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    30W /  70W |   1910MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dasxAZwXPoA2",
        "outputId": "db7302a3-a4fc-4d39-abe2-c7ba1d2113f1"
      },
      "source": [
        "# Check devices using TF\n",
        "tf.config.list_physical_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove logs\n",
        "!ls .\n",
        "!ls logs\n",
        "!pwd\n",
        "!rm -rf logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1sLrVRSSN4D",
        "outputId": "af50bc40-ca62-42ae-f34f-614917ae86ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logs  sample_data\n",
            "20221025-130321  20221025-130649\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVRfwL_3ihXc"
      },
      "source": [
        "<h2>Dropout - logiczna (i losowa) redukcja neuronów</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM89L4g4r5z3"
      },
      "source": [
        "W [1] G. Hinton wraz z współpracownikami pokazali znaczenie losowej redukcji neuronów (ang. dropout) na redukcję problemu nadmiernego dopasowania modelu do danych.\n",
        "\n",
        "W kolejnych epokach losowa wybrana pula neuronów jest eliminowana z prawdopodobieństwem q=1-p (q – dropout rate, p – retain ratio). Zatem można sobie wyobrazić, że w każdej epoce trenowana jest jakby trochę inna architektura modelu. Na koniec eksperymentów mamy efekt uogólnienia różnych modeli dla wejściowego zestawu danych.\n",
        "\n",
        "Przypomina to trochę efekt podobny jak dla poznanych w czasie wykładu z uczenia maszynowego metod typu bagging (bootstrap aggregation).\n",
        "\n",
        "W implementacjach praktycznych nie są usuwane neurony, ale ustawiane są losowo wartości 0 na wylosowanych pozycjach tensora wejściowego danej warstwy. Pozostałe wartości tensora wejściowego są normalizowane (skalowane przez wartości s=1/(1-q)).\n",
        "\n",
        "[1] G. Hinton i inni, 2012, https://arxiv.org/abs/1207.0580\n",
        "\n",
        "\n",
        "Metodę redukcji neuronów implementuje się jako funkcję w postaci warstwy modelu głębokiego. Przykładowo w TF:\n",
        "\n",
        "```Python\n",
        "layer = tf.keras.layers.Dropout(rate=0.2)\n",
        "```\n",
        "\n",
        "Zapoznajmy się z prostym przykładem:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcSCrvEsEZLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3524c72b-92d0-4b8d-df9d-a91fcd9d2111"
      },
      "source": [
        "layer_drop = tf.keras.layers.Dropout(rate=0.5, input_shape=(2,))\n",
        "simple_input_data = np.arange(8).reshape(4, 2).astype(np.float32)+1\n",
        "print(\"Simple input data: \\n\", simple_input_data)\n",
        "\n",
        "outputs = layer_drop(simple_input_data, training=True)\n",
        "print(\"\\nResult of the dropout operation: \\n\", outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple input data: \n",
            " [[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]\n",
            " [7. 8.]]\n",
            "\n",
            "Result of the dropout operation: \n",
            " tf.Tensor(\n",
            "[[ 2.  0.]\n",
            " [ 6.  0.]\n",
            " [ 0. 12.]\n",
            " [ 0. 16.]], shape=(4, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMlIEYtCiiRj"
      },
      "source": [
        "Zróbmy eksperyment ponownie z danymi CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruGHlzH0mUc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "e8fcc184-a3a3-4b86-b8ef-6a7c181029cc"
      },
      "source": [
        "# Load data and split to training and test datasets\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "class_names = [\n",
        "'airplane','automobile','bird', 'cat', 'deer' ,\n",
        "'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Data properties\n",
        "image_width = 32;\n",
        "image_height = 32;\n",
        "image_components = 3\n",
        "\n",
        "# Show an example\n",
        "example = 200\n",
        "class_id = y_train[example].item()\n",
        "\n",
        "plt.rcParams[\"axes.grid\"] = False\n",
        "plt.imshow(x_train[example])\n",
        "print(\"True original label :\", class_id, class_names[class_id])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True original label : 6 frog\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcWE8pYnCR0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96eb8bd5-782b-4d89-a12b-c22ab79baa14"
      },
      "source": [
        "# Show the shape of input data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "print(\"X train dataset shape: \", x_train.shape)\n",
        "print(\"Max value in X train: \", np.max(x_train))\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train dataset shape:  (50000, 32, 32, 3)\n",
            "Max value in X train:  255.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OARzl-aKVbQC"
      },
      "source": [
        "# Normalize image data\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# You can try to standsardize images (using mean and std. dev.)\n",
        "\n",
        "# Set some training parameters\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "no_of_classes = 10\n",
        "learning_rate = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARm3ixu4p7kL"
      },
      "source": [
        "Ponownie wykorzystajmy architekturę podobną do modelu LeNet-5 opublikowany przez Yanna LeCuna i innych w 1998 roku.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL0BCg0RamkO"
      },
      "source": [
        "def get_LeNet5_model_w_droput():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=x_train.shape[1:], name=\"input\"),\n",
        "      tf.keras.layers.Conv2D(6, kernel_size=5, activation='relu',\n",
        "                              name=\"c1\"),\n",
        "      tf.keras.layers.AveragePooling2D(pool_size=(2,2), name=\"s1\"),\n",
        "      tf.keras.layers.Conv2D(16, kernel_size=5, activation='relu',\n",
        "                              name=\"c3\"),\n",
        "      tf.keras.layers.AveragePooling2D(pool_size=(2,2), name=\"s4\"),\n",
        "\n",
        "      ## use this version (2 layers)\n",
        "      tf.keras.layers.Conv2D(120, kernel_size=5, activation='relu',\n",
        "                              name=\"c5\"),\n",
        "      tf.keras.layers.Flatten(),  # make data flat to use dense layers\n",
        "\n",
        "      # OR this version instead (2 layers)\n",
        "      # tf.keras.layers.Flatten(),  # make data flat to use dense layers\n",
        "      # tf.keras.layers.Dense(120, activation = 'relu', name=\"C5\"),\n",
        "\n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.Dense(84, activation='relu', name=\"d6\"),\n",
        "      tf.keras.layers.Dense(no_of_classes, activation='softmax', name=\"d7\")\n",
        "\n",
        "    ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKtpQnBchQgN"
      },
      "source": [
        "Przygotujmy ustawienia procedury uczenia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auRtcSfWKHVn"
      },
      "source": [
        "sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urvRxl0LgPgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa047638-55af-4ae2-ad3d-25997e206ef0"
      },
      "source": [
        "# Use \"logs\" folder to store data for TensorBoard\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "!ls\n",
        "\n",
        "# Define callback function for TensorBoard\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkfsBmo0gYa8"
      },
      "source": [
        "def train_model(model, callbacks, opt, epochs=10, batch_size=32, iterations=None):\n",
        "  \"\"\"\n",
        "  Train model - use some global variable (you can modify the definition\n",
        "                to make this function more univeral)\n",
        "  model - model to train\n",
        "  callbacks = list of callback functions\n",
        "  opt - type of the optimizer\n",
        "  epochs - number of epochs\n",
        "  batch_size = sieze of a batch of data\n",
        "  iterations - set steps_per_epoch\n",
        "                if None -> equal to the number of samples in your\n",
        "                dataset divided by the batch size\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  model.compile(\n",
        "    # Choose the optimizer\n",
        "    optimizer=opt,\n",
        "    loss='categorical_crossentropy',\n",
        "    # Introduce additional metric\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  model.fit(x=x_train,\n",
        "            y=y_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            steps_per_epoch=iterations,\n",
        "            # Use test data to perform validation\n",
        "            validation_data=(x_test, y_test),\n",
        "            # Assign reference to the TB callback function\n",
        "            callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of25URSMQ1Fc"
      },
      "source": [
        "# Learning rate scheduler\n",
        "def scheduler(epoch, lr):\n",
        "\n",
        "  if epoch < 5:\n",
        "    eta = 0.01\n",
        "  else:\n",
        "    eta = lr * tf.math.exp(-0.02)\n",
        "\n",
        "  if eta < 0.005:\n",
        "    eta = 0.001\n",
        "\n",
        "  print(\"Learning rate is: \", eta)\n",
        "  return eta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyUg1QHjiqHt"
      },
      "source": [
        "Przeprowadźmy proces uczenia modelu wykorzystującego warstwę Dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr1kJ6XQbIC3",
        "outputId": "98f6066d-03f9-457d-9c6f-36feec85d079"
      },
      "source": [
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "callbacks = [lr_scheduler,tensorboard_callback]\n",
        "\n",
        "model_to_train = get_LeNet5_model_w_droput()\n",
        "\n",
        "# Redefine hiperparameters - use more epoch in the experiments\n",
        "epochs = 40\n",
        "# epochs = 5\n",
        "learning_rate = 0.01\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
        "# adam = tf.keras.optimizers.Adam(learning_rate=learning_rate*0.1, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Start training\n",
        "train_model(model_to_train, callbacks=callbacks, opt=sgd,\n",
        "            epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate is:  0.01\n",
            "Epoch 1/40\n",
            "782/782 [==============================] - 5s 5ms/step - loss: 1.8993 - accuracy: 0.3007 - val_loss: 1.6098 - val_accuracy: 0.4171 - lr: 0.0100\n",
            "Learning rate is:  0.01\n",
            "Epoch 2/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.5507 - accuracy: 0.4369 - val_loss: 1.4343 - val_accuracy: 0.4826 - lr: 0.0100\n",
            "Learning rate is:  0.01\n",
            "Epoch 3/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.4309 - accuracy: 0.4868 - val_loss: 1.3370 - val_accuracy: 0.5165 - lr: 0.0100\n",
            "Learning rate is:  0.01\n",
            "Epoch 4/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.3653 - accuracy: 0.5086 - val_loss: 1.3293 - val_accuracy: 0.5188 - lr: 0.0100\n",
            "Learning rate is:  0.01\n",
            "Epoch 5/40\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.3060 - accuracy: 0.5313 - val_loss: 1.2387 - val_accuracy: 0.5519 - lr: 0.0100\n",
            "Learning rate is:  tf.Tensor(0.009801987, shape=(), dtype=float32)\n",
            "Epoch 6/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.2660 - accuracy: 0.5457 - val_loss: 1.2117 - val_accuracy: 0.5657 - lr: 0.0098\n",
            "Learning rate is:  tf.Tensor(0.009607894, shape=(), dtype=float32)\n",
            "Epoch 7/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.2207 - accuracy: 0.5655 - val_loss: 1.1882 - val_accuracy: 0.5762 - lr: 0.0096\n",
            "Learning rate is:  tf.Tensor(0.009417646, shape=(), dtype=float32)\n",
            "Epoch 8/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1889 - accuracy: 0.5777 - val_loss: 1.1910 - val_accuracy: 0.5764 - lr: 0.0094\n",
            "Learning rate is:  tf.Tensor(0.009231164, shape=(), dtype=float32)\n",
            "Epoch 9/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1575 - accuracy: 0.5884 - val_loss: 1.1262 - val_accuracy: 0.5968 - lr: 0.0092\n",
            "Learning rate is:  tf.Tensor(0.009048375, shape=(), dtype=float32)\n",
            "Epoch 10/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.1260 - accuracy: 0.5987 - val_loss: 1.1138 - val_accuracy: 0.6001 - lr: 0.0090\n",
            "Learning rate is:  tf.Tensor(0.008869206, shape=(), dtype=float32)\n",
            "Epoch 11/40\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 1.0988 - accuracy: 0.6080 - val_loss: 1.2198 - val_accuracy: 0.5735 - lr: 0.0089\n",
            "Learning rate is:  tf.Tensor(0.008693583, shape=(), dtype=float32)\n",
            "Epoch 12/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.0692 - accuracy: 0.6186 - val_loss: 1.1395 - val_accuracy: 0.5947 - lr: 0.0087\n",
            "Learning rate is:  tf.Tensor(0.008521439, shape=(), dtype=float32)\n",
            "Epoch 13/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.0482 - accuracy: 0.6267 - val_loss: 1.1975 - val_accuracy: 0.5837 - lr: 0.0085\n",
            "Learning rate is:  tf.Tensor(0.0083527025, shape=(), dtype=float32)\n",
            "Epoch 14/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.0236 - accuracy: 0.6325 - val_loss: 1.0640 - val_accuracy: 0.6242 - lr: 0.0084\n",
            "Learning rate is:  tf.Tensor(0.008187308, shape=(), dtype=float32)\n",
            "Epoch 15/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.0088 - accuracy: 0.6407 - val_loss: 1.0495 - val_accuracy: 0.6286 - lr: 0.0082\n",
            "Learning rate is:  tf.Tensor(0.008025189, shape=(), dtype=float32)\n",
            "Epoch 16/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.9854 - accuracy: 0.6486 - val_loss: 1.0566 - val_accuracy: 0.6241 - lr: 0.0080\n",
            "Learning rate is:  tf.Tensor(0.007866279, shape=(), dtype=float32)\n",
            "Epoch 17/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.9681 - accuracy: 0.6543 - val_loss: 1.0316 - val_accuracy: 0.6341 - lr: 0.0079\n",
            "Learning rate is:  tf.Tensor(0.0077105165, shape=(), dtype=float32)\n",
            "Epoch 18/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.9507 - accuracy: 0.6584 - val_loss: 1.0427 - val_accuracy: 0.6317 - lr: 0.0077\n",
            "Learning rate is:  tf.Tensor(0.007557838, shape=(), dtype=float32)\n",
            "Epoch 19/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.9381 - accuracy: 0.6644 - val_loss: 1.1308 - val_accuracy: 0.6116 - lr: 0.0076\n",
            "Learning rate is:  tf.Tensor(0.007408183, shape=(), dtype=float32)\n",
            "Epoch 20/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.9216 - accuracy: 0.6726 - val_loss: 1.0372 - val_accuracy: 0.6366 - lr: 0.0074\n",
            "Learning rate is:  tf.Tensor(0.0072614914, shape=(), dtype=float32)\n",
            "Epoch 21/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.9111 - accuracy: 0.6765 - val_loss: 1.0388 - val_accuracy: 0.6390 - lr: 0.0073\n",
            "Learning rate is:  tf.Tensor(0.0071177045, shape=(), dtype=float32)\n",
            "Epoch 22/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.8986 - accuracy: 0.6791 - val_loss: 1.0419 - val_accuracy: 0.6365 - lr: 0.0071\n",
            "Learning rate is:  tf.Tensor(0.0069767646, shape=(), dtype=float32)\n",
            "Epoch 23/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.8840 - accuracy: 0.6857 - val_loss: 1.0504 - val_accuracy: 0.6340 - lr: 0.0070\n",
            "Learning rate is:  tf.Tensor(0.0068386155, shape=(), dtype=float32)\n",
            "Epoch 24/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.8717 - accuracy: 0.6889 - val_loss: 1.0255 - val_accuracy: 0.6388 - lr: 0.0068\n",
            "Learning rate is:  tf.Tensor(0.0067032017, shape=(), dtype=float32)\n",
            "Epoch 25/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.8562 - accuracy: 0.6938 - val_loss: 1.1268 - val_accuracy: 0.6168 - lr: 0.0067\n",
            "Learning rate is:  tf.Tensor(0.0065704696, shape=(), dtype=float32)\n",
            "Epoch 26/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.8495 - accuracy: 0.6956 - val_loss: 1.0140 - val_accuracy: 0.6434 - lr: 0.0066\n",
            "Learning rate is:  tf.Tensor(0.0064403657, shape=(), dtype=float32)\n",
            "Epoch 27/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.8375 - accuracy: 0.7026 - val_loss: 1.0346 - val_accuracy: 0.6411 - lr: 0.0064\n",
            "Learning rate is:  tf.Tensor(0.006312838, shape=(), dtype=float32)\n",
            "Epoch 28/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.8310 - accuracy: 0.7021 - val_loss: 1.0306 - val_accuracy: 0.6381 - lr: 0.0063\n",
            "Learning rate is:  tf.Tensor(0.0061878352, shape=(), dtype=float32)\n",
            "Epoch 29/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.8230 - accuracy: 0.7039 - val_loss: 1.0512 - val_accuracy: 0.6400 - lr: 0.0062\n",
            "Learning rate is:  tf.Tensor(0.006065308, shape=(), dtype=float32)\n",
            "Epoch 30/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.8106 - accuracy: 0.7089 - val_loss: 1.0438 - val_accuracy: 0.6423 - lr: 0.0061\n",
            "Learning rate is:  tf.Tensor(0.005945207, shape=(), dtype=float32)\n",
            "Epoch 31/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.8042 - accuracy: 0.7104 - val_loss: 1.0244 - val_accuracy: 0.6458 - lr: 0.0059\n",
            "Learning rate is:  tf.Tensor(0.005827484, shape=(), dtype=float32)\n",
            "Epoch 32/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.7907 - accuracy: 0.7150 - val_loss: 1.0301 - val_accuracy: 0.6513 - lr: 0.0058\n",
            "Learning rate is:  tf.Tensor(0.0057120924, shape=(), dtype=float32)\n",
            "Epoch 33/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.7846 - accuracy: 0.7167 - val_loss: 1.0124 - val_accuracy: 0.6525 - lr: 0.0057\n",
            "Learning rate is:  tf.Tensor(0.0055989856, shape=(), dtype=float32)\n",
            "Epoch 34/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.7703 - accuracy: 0.7236 - val_loss: 1.0562 - val_accuracy: 0.6421 - lr: 0.0056\n",
            "Learning rate is:  tf.Tensor(0.005488118, shape=(), dtype=float32)\n",
            "Epoch 35/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.7696 - accuracy: 0.7221 - val_loss: 1.0362 - val_accuracy: 0.6535 - lr: 0.0055\n",
            "Learning rate is:  tf.Tensor(0.0053794463, shape=(), dtype=float32)\n",
            "Epoch 36/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.7631 - accuracy: 0.7266 - val_loss: 1.0456 - val_accuracy: 0.6483 - lr: 0.0054\n",
            "Learning rate is:  tf.Tensor(0.0052729263, shape=(), dtype=float32)\n",
            "Epoch 37/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.7549 - accuracy: 0.7291 - val_loss: 1.0350 - val_accuracy: 0.6442 - lr: 0.0053\n",
            "Learning rate is:  tf.Tensor(0.0051685153, shape=(), dtype=float32)\n",
            "Epoch 38/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.7478 - accuracy: 0.7298 - val_loss: 1.0301 - val_accuracy: 0.6537 - lr: 0.0052\n",
            "Learning rate is:  tf.Tensor(0.0050661718, shape=(), dtype=float32)\n",
            "Epoch 39/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.7402 - accuracy: 0.7332 - val_loss: 1.0596 - val_accuracy: 0.6468 - lr: 0.0051\n",
            "Learning rate is:  0.001\n",
            "Epoch 40/40\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.6749 - accuracy: 0.7576 - val_loss: 1.0181 - val_accuracy: 0.6610 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "8XKh_RwNeX3Y",
        "outputId": "85f25e5e-a2ba-46f3-d3a7-f514e992a85e"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 394), started 0:11:43 ago. (Use '!kill 394' to kill it.)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w08myTmj79C"
      },
      "source": [
        "Możemu zauważyć, że zredukowaliśmy problem nadmiernego dopasowania modelu do danych."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4rWStk2i5zN"
      },
      "source": [
        "<h2>Batch normalization - standardyzacja porcji danych</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jorldxfpc7CK"
      },
      "source": [
        "BN - standardyzacja danych polega na zastosowaniu funkcji, która:\n",
        "- standardyzuje porcję danych względem wartości średniej i odchylenia standardowego dla PORCJI danych $\\hat{x}$ =(batch-mi(batch))/std_dev(batch)\n",
        "- poszukuje parametrów $\\gamma$ i $\\beta$ skalujących uzyskane wartości: $y=\\gamma * \\hat{x} +\\beta $\n",
        "\n",
        "Standardyzacja porcji danych dla sieci CNN powinna być realizowana po wyjściu modelu liniowego, przez zastosowaniem funkcji aktywacji, tj. operacja\n",
        "z = a (Wh+b)\n",
        "jest zamieniana na:\n",
        "z=a (BN(Wh)).\n",
        "\n",
        "W praktyce niektóre zespoły wskazują pozytywne wyniki uczenia i inferencji przy stosowaniu BN po funkcji aktywacji. Inni podkreślają, że zależeć to może od rodzaju funkcji aktywacji.\n",
        "\n",
        "W TensorFlow możemy wykorzystać warstwę (funkcję):\n",
        "```Python\n",
        "tf.keras.layers.BatchNormalization()\n",
        "```\n",
        "\n",
        "Dodajmy ją do naszego wcześniejszego modelu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGqXTtzVc7eJ"
      },
      "source": [
        "def get_LeNet5_model_w_BN():\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=x_train.shape[1:], name=\"input\"),\n",
        "      tf.keras.layers.Conv2D(6, kernel_size=5, activation=None, name=\"c1\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.ReLU(),\n",
        "      tf.keras.layers.AveragePooling2D(pool_size=(2,2), name=\"s1\"),\n",
        "\n",
        "      tf.keras.layers.Conv2D(16, kernel_size=5, activation=None, name=\"c3\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.ReLU(),\n",
        "      tf.keras.layers.AveragePooling2D(pool_size=(2,2), name=\"s4\"),\n",
        "\n",
        "      ## use this version (2 layers)\n",
        "      tf.keras.layers.Conv2D(120, kernel_size=5, activation=None, name=\"c5\"),\n",
        "      tf.keras.layers.ReLU(),\n",
        "\n",
        "      tf.keras.layers.Flatten(),  # make data flat to use dense layers\n",
        "\n",
        "      # OR this version instead (2 layers)\n",
        "      # tf.keras.layers.Flatten(),  # make data flat to use dense layers\n",
        "      # tf.keras.layers.Dense(120, activation = 'relu', name=\"C5\"),\n",
        "\n",
        "      # Droput after all BN operations\n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.Dense(84, activation='relu'),\n",
        "      tf.keras.layers.Dense(no_of_classes, activation='softmax')\n",
        "\n",
        "    ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q_B52m7mRc1"
      },
      "source": [
        "I przeprowadźmy trening modelu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyfjmAVndbMO",
        "outputId": "1d40e7cb-798d-495a-ca35-841e8d241098"
      },
      "source": [
        "# Use \"logs\" folder to store data for TensorBoard\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# Define callback function for TensorBoard\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "# callbacks = [lr_scheduler,tensorboard_callback]\n",
        "callbacks = [tensorboard_callback]\n",
        "\n",
        "model_to_train = get_LeNet5_model_w_BN()\n",
        "\n",
        "# Redefine hiperparameters - use more epoch in the experiments\n",
        "epochs = 40\n",
        "# epochs = 5\n",
        "learning_rate = 0.01\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
        "# adam = tf.keras.optimizers.Adam(learning_rate=learning_rate*0.1, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Start training\n",
        "# For BN use full batches - to have stable moving mean and var for inference\n",
        "train_model(model_to_train, callbacks=callbacks, opt=sgd,\n",
        "            epochs=epochs, batch_size=batch_size,\n",
        "            iterations=int(x_train.shape[0]/batch_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "781/781 [==============================] - 5s 6ms/step - loss: 1.5939 - accuracy: 0.4134 - val_loss: 1.5500 - val_accuracy: 0.4547\n",
            "Epoch 2/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 1.3555 - accuracy: 0.5118 - val_loss: 1.4215 - val_accuracy: 0.4965\n",
            "Epoch 3/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 1.2552 - accuracy: 0.5494 - val_loss: 1.3604 - val_accuracy: 0.5079\n",
            "Epoch 4/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 1.1879 - accuracy: 0.5758 - val_loss: 1.2653 - val_accuracy: 0.5507\n",
            "Epoch 5/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 1.1314 - accuracy: 0.5973 - val_loss: 1.1569 - val_accuracy: 0.5925\n",
            "Epoch 6/40\n",
            "781/781 [==============================] - 4s 6ms/step - loss: 1.0917 - accuracy: 0.6106 - val_loss: 1.1545 - val_accuracy: 0.5985\n",
            "Epoch 7/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 1.0562 - accuracy: 0.6247 - val_loss: 1.1352 - val_accuracy: 0.5986\n",
            "Epoch 8/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 1.0267 - accuracy: 0.6354 - val_loss: 1.2020 - val_accuracy: 0.5762\n",
            "Epoch 9/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 1.0054 - accuracy: 0.6414 - val_loss: 1.1189 - val_accuracy: 0.6089\n",
            "Epoch 10/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.9813 - accuracy: 0.6514 - val_loss: 1.0559 - val_accuracy: 0.6295\n",
            "Epoch 11/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.9557 - accuracy: 0.6607 - val_loss: 1.1516 - val_accuracy: 0.6049\n",
            "Epoch 12/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.9410 - accuracy: 0.6664 - val_loss: 1.0787 - val_accuracy: 0.6230\n",
            "Epoch 13/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.9204 - accuracy: 0.6720 - val_loss: 1.0432 - val_accuracy: 0.6353\n",
            "Epoch 14/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.9002 - accuracy: 0.6794 - val_loss: 1.0253 - val_accuracy: 0.6452\n",
            "Epoch 15/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.8899 - accuracy: 0.6819 - val_loss: 1.0591 - val_accuracy: 0.6414\n",
            "Epoch 16/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.8763 - accuracy: 0.6879 - val_loss: 1.0437 - val_accuracy: 0.6392\n",
            "Epoch 17/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.8600 - accuracy: 0.6936 - val_loss: 1.1050 - val_accuracy: 0.6331\n",
            "Epoch 18/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.8474 - accuracy: 0.6971 - val_loss: 0.9746 - val_accuracy: 0.6603\n",
            "Epoch 19/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.8355 - accuracy: 0.7000 - val_loss: 0.9782 - val_accuracy: 0.6663\n",
            "Epoch 20/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.8253 - accuracy: 0.7051 - val_loss: 1.1426 - val_accuracy: 0.6139\n",
            "Epoch 21/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.8183 - accuracy: 0.7077 - val_loss: 0.9611 - val_accuracy: 0.6645\n",
            "Epoch 22/40\n",
            "781/781 [==============================] - 5s 6ms/step - loss: 0.8071 - accuracy: 0.7106 - val_loss: 1.0218 - val_accuracy: 0.6543\n",
            "Epoch 23/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.8045 - accuracy: 0.7120 - val_loss: 1.1333 - val_accuracy: 0.6192\n",
            "Epoch 24/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7909 - accuracy: 0.7162 - val_loss: 1.0362 - val_accuracy: 0.6457\n",
            "Epoch 25/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7814 - accuracy: 0.7206 - val_loss: 0.9752 - val_accuracy: 0.6657\n",
            "Epoch 26/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7771 - accuracy: 0.7215 - val_loss: 0.9707 - val_accuracy: 0.6732\n",
            "Epoch 27/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7604 - accuracy: 0.7262 - val_loss: 1.0659 - val_accuracy: 0.6360\n",
            "Epoch 28/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7581 - accuracy: 0.7268 - val_loss: 0.9933 - val_accuracy: 0.6668\n",
            "Epoch 29/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7515 - accuracy: 0.7300 - val_loss: 0.9696 - val_accuracy: 0.6724\n",
            "Epoch 30/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7450 - accuracy: 0.7317 - val_loss: 1.0430 - val_accuracy: 0.6543\n",
            "Epoch 31/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7361 - accuracy: 0.7369 - val_loss: 0.9759 - val_accuracy: 0.6729\n",
            "Epoch 32/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7364 - accuracy: 0.7359 - val_loss: 1.0479 - val_accuracy: 0.6591\n",
            "Epoch 33/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7258 - accuracy: 0.7379 - val_loss: 1.0006 - val_accuracy: 0.6643\n",
            "Epoch 34/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7247 - accuracy: 0.7377 - val_loss: 1.1125 - val_accuracy: 0.6422\n",
            "Epoch 35/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7137 - accuracy: 0.7432 - val_loss: 1.0215 - val_accuracy: 0.6628\n",
            "Epoch 36/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7071 - accuracy: 0.7442 - val_loss: 1.0844 - val_accuracy: 0.6499\n",
            "Epoch 37/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.7003 - accuracy: 0.7457 - val_loss: 1.0969 - val_accuracy: 0.6381\n",
            "Epoch 38/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.6996 - accuracy: 0.7473 - val_loss: 1.0159 - val_accuracy: 0.6663\n",
            "Epoch 39/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.6978 - accuracy: 0.7472 - val_loss: 1.1455 - val_accuracy: 0.6221\n",
            "Epoch 40/40\n",
            "781/781 [==============================] - 4s 5ms/step - loss: 0.6907 - accuracy: 0.7508 - val_loss: 1.0538 - val_accuracy: 0.6567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngzkGTjQmagP"
      },
      "source": [
        "Możemy zauważyć, że zwykle procesu uczenia modelu z BN wskazuje szybsze uzyskiwanie lepszych wartośc miar jakości."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4wqrFichnaw"
      },
      "source": [
        "Własne eksperymenty - jakie kombinacje poznanych dotądoperacji i parametrów dają najlepsze rezultaty dla modelu bazującego na LeNet-5?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIpYL7uTqUF5"
      },
      "source": [
        "<center>\n",
        "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n",
        "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
        "    </center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eO88wDGqUwy"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}