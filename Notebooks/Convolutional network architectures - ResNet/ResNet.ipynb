{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rze6EnG6fTik"
      },
      "source": [
        "##### AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Programu Operacyjnego Polska Cyfrowa na lata 2014-2020\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "OuaA8rFCfXTP",
        "outputId": "1abaa393-26c5-4bbe-d2ba-84f263c186d5"
      },
      "source": [
        "#@title\n",
        "%%html\n",
        "<iframe src=\"https://www.polskacyfrowa.gov.pl/media/48246/FE_POPC_poziom_pl-1_rgb.jpg\" width=\"800\"></iframe>\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<iframe src=\"https://www.polskacyfrowa.gov.pl/media/48246/FE_POPC_poziom_pl-1_rgb.jpg\" width=\"800\"></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6hP8DZKln80"
      },
      "source": [
        "# Uczenie głębokie\n",
        "\n",
        "Jacek Rumiński, Politechnika Gdańska, Wydział ETI, Katedra Inżynierii Biomedycznej\n",
        "\n",
        "**Wykład 6:** Architektury sieci splotowych - ResNet\n",
        "\n",
        "**Przykład (3):** ResNet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yfD5HsRfosc"
      },
      "source": [
        "W ramach tego notatnika przedstawiamy przykładowe kody umożliwiające praktyczne zapoznanie się elementami architektur bazujących na ResNet.\n",
        "\n",
        "Szczegóły dotyczące modelu można znaleźć w:\n",
        "\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun (2015) Deep Residual Learning for Image Recognition https://arxiv.org/abs/1512.03385\n",
        "\n",
        "\n",
        "Wskażmy pakiety, z jakich będziemy korzystać:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL1UM5173hO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac918e6-f2bb-4566-b057-db51a47d1824"
      },
      "source": [
        "import numpy as np\n",
        "import datetime, os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import seaborn as sns; sns.set_theme()\n",
        "from matplotlib.colors import ListedColormap\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "font = {'family' : 'DejaVu Sans',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 22}\n",
        "\n",
        "# You can try to change your Google Colab environment to GPU\n",
        "print(tf.__version__)\n",
        "\n",
        "# You can always check which packages are installed using:\n",
        "# !pip list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGFHaMk0HN9G",
        "outputId": "d7d7dd84-1788-4e37-829c-5169a284fdbe"
      },
      "source": [
        "# Check if you have GPU resources (Runtime / Change runtime type -> GPU)\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 19 11:23:43 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dasxAZwXPoA2",
        "outputId": "2fcb7c98-40a4-4181-c25b-282faec0eba8"
      },
      "source": [
        "# Check devices using TF\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print(physical_devices)\n",
        "\n",
        "try:\n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "  # Invalid device or cannot modify virtual devices once initialized.\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UOSpuaFPT0s"
      },
      "source": [
        "Przedstawmy budowę podstawowej wersji bloku ResNet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3xKyDZuOXe_"
      },
      "source": [
        "def residual_block(img_input, filters, rescale=False, b_name='1'):\n",
        "\n",
        "    ch_axis = -1 # defualt (channel_last)\n",
        "    stride = 1\n",
        "    w_init = 'he_uniform'\n",
        "    n = '_'+b_name\n",
        "\n",
        "    # Store skip connection\n",
        "    skip_connection = img_input\n",
        "\n",
        "    # Optionally add skip connection with Conv2D(1x1) and BN\n",
        "    if rescale == True:\n",
        "      stride = 2\n",
        "      skip_connection = tf.keras.layers.Conv2D(filters, (1,1),\n",
        "                                               strides=(stride,stride),\n",
        "                                               kernel_initializer=w_init,\n",
        "                                               name='skip_conv'+n)(skip_connection)\n",
        "      skip_connection = tf.keras.layers.BatchNormalization(axis=ch_axis,\n",
        "                                                           name='skip_bn'+n)(skip_connection)\n",
        "\n",
        "    # First set of layers\n",
        "    x = tf.keras.layers.Conv2D(filters, (3,3), padding ='same',\n",
        "                               strides=(stride,stride),\n",
        "                               kernel_initializer=w_init,\n",
        "                               name='conv_1'+n)(img_input)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=ch_axis, name='bn_1'+n)(x)\n",
        "    x = tf.keras.layers.Activation('relu', name='act_1'+n)(x)\n",
        "    # Second set of layers - default stride!!!\n",
        "    x = tf.keras.layers.Conv2D(filters, (3,3), padding = 'same',\n",
        "                               kernel_initializer=w_init, name='conv_2'+n)(x)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=ch_axis, name='bn_2'+n)(x)\n",
        "\n",
        "    # Add connections\n",
        "    x = tf.keras.layers.Add()([x, skip_connection])\n",
        "    output = tf.keras.layers.Activation('relu', name='act_block'+n)(x)\n",
        "\n",
        "    model = tf.keras.Model(img_input, output, name='residual_block'+n)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ABuU9i_HxSF"
      },
      "source": [
        "Zastosujmy blok i zapoznajmy się w wydrukiem informacji o poszczególnych warstwach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1WXD4oaTI2f",
        "outputId": "4cae0500-7de4-49cb-94f6-2fa3eed6e392"
      },
      "source": [
        "data = np.ones((1,28,28,64))\n",
        "input_shape = (data.shape[1],data.shape[2],data.shape[3])\n",
        "img_input = tf.keras.layers.Input(shape=input_shape, name='b_input')\n",
        "model_no_reduce = residual_block(img_input, 64)\n",
        "print(model_no_reduce(data).shape)\n",
        "\n",
        "model_no_reduce.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28, 64)\n",
            "Model: \"residual_block_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " b_input (InputLayer)           [(None, 28, 28, 64)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv_1_1 (Conv2D)              (None, 28, 28, 64)   36928       ['b_input[0][0]']                \n",
            "                                                                                                  \n",
            " bn_1_1 (BatchNormalization)    (None, 28, 28, 64)   256         ['conv_1_1[0][0]']               \n",
            "                                                                                                  \n",
            " act_1_1 (Activation)           (None, 28, 28, 64)   0           ['bn_1_1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv_2_1 (Conv2D)              (None, 28, 28, 64)   36928       ['act_1_1[0][0]']                \n",
            "                                                                                                  \n",
            " bn_2_1 (BatchNormalization)    (None, 28, 28, 64)   256         ['conv_2_1[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 28, 28, 64)   0           ['bn_2_1[0][0]',                 \n",
            "                                                                  'b_input[0][0]']                \n",
            "                                                                                                  \n",
            " act_block_1 (Activation)       (None, 28, 28, 64)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 74,368\n",
            "Trainable params: 74,112\n",
            "Non-trainable params: 256\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL8SIgatII_z"
      },
      "source": [
        "Zastosujmy blok w wersji ze skalowaniem danych w połaczeniu recydualnym i zapoznajmy się w wydrukiem informacji o poszczególnych warstwach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT1BmOT3SNP0",
        "outputId": "66eb8e46-dfbb-4402-faf8-a4e03e5e2bdb"
      },
      "source": [
        "data = np.ones((1,28,28,3))\n",
        "input_shape = (data.shape[1],data.shape[2],data.shape[3])\n",
        "img_input = tf.keras.layers.Input(shape=input_shape, name='b_input')\n",
        "\n",
        "#Input depth 256 is not equal to output depth 64, so we need to rescale\n",
        "model_with_reduce = residual_block(img_input=img_input, filters=64, rescale=True)\n",
        "print(model_with_reduce(data).shape)\n",
        "\n",
        "model_with_reduce.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 14, 14, 64)\n",
            "Model: \"residual_block_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " b_input (InputLayer)           [(None, 28, 28, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv_1_1 (Conv2D)              (None, 14, 14, 64)   1792        ['b_input[0][0]']                \n",
            "                                                                                                  \n",
            " bn_1_1 (BatchNormalization)    (None, 14, 14, 64)   256         ['conv_1_1[0][0]']               \n",
            "                                                                                                  \n",
            " act_1_1 (Activation)           (None, 14, 14, 64)   0           ['bn_1_1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv_2_1 (Conv2D)              (None, 14, 14, 64)   36928       ['act_1_1[0][0]']                \n",
            "                                                                                                  \n",
            " skip_conv_1 (Conv2D)           (None, 14, 14, 64)   256         ['b_input[0][0]']                \n",
            "                                                                                                  \n",
            " bn_2_1 (BatchNormalization)    (None, 14, 14, 64)   256         ['conv_2_1[0][0]']               \n",
            "                                                                                                  \n",
            " skip_bn_1 (BatchNormalization)  (None, 14, 14, 64)  256         ['skip_conv_1[0][0]']            \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 14, 14, 64)   0           ['bn_2_1[0][0]',                 \n",
            "                                                                  'skip_bn_1[0][0]']              \n",
            "                                                                                                  \n",
            " act_block_1 (Activation)       (None, 14, 14, 64)   0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 39,744\n",
            "Trainable params: 39,360\n",
            "Non-trainable params: 384\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu60Xq5sIeKZ"
      },
      "source": [
        "Spróbujmy zbudować model złożony dwóch bloków recydualnych."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Y87-upHHDN"
      },
      "source": [
        "def get_Model(input_shape, no_of_classes):\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    #print(x.shape[1:])\n",
        "\n",
        "    x_in_1 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_1 = residual_block(x_in_1, 64, rescale=False, b_name='1')\n",
        "    x = base_model_1(x, training=True)\n",
        "\n",
        "    x_in_2 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_2 = residual_block(x_in_2, 256, rescale=True, b_name='2')\n",
        "    x = base_model_2(x, training=True)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x =  tf.keras.layers.Dense(256)(x)\n",
        "    outputs = tf.keras.layers.Dense(no_of_classes, activation='softmax' )(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs, name='simple_res_net')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMlIEYtCiiRj"
      },
      "source": [
        "Ponownie będziemy chcieli zastosowań nowy model dla danych CIFAR-10. Przykład wykorzystamy jedynie do demonstracji użycia modelu - nie jest on optymalizaowany ze względu na wynik jakości rozpatrywanego problemu klasyfikcji danych. Również kody źródłowe są tak skonstruowane, aby przedstawić kolejne kroki działań i nie są optymalizowane.\n",
        "\n",
        "Zachęcem do eksperymentowania na innych bazach danych takich jak CIFAR-100, ImageNet, itp.\n",
        "\n",
        "Zróbmy eksperyment ponownie z danymi CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruGHlzH0mUc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "76de77b6-436c-4aba-f453-4cd2ca673001"
      },
      "source": [
        "# Load data and split to training and test datasets\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "class_names = [\n",
        "'airplane','automobile','bird', 'cat', 'deer' ,\n",
        "'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Data properties\n",
        "image_width = 32;\n",
        "image_height = 32;\n",
        "image_components = 3\n",
        "\n",
        "# Show an example\n",
        "example = 200\n",
        "class_id = y_train[example].item()\n",
        "\n",
        "plt.rcParams[\"axes.grid\"] = False\n",
        "plt.imshow(x_train[example])\n",
        "print(\"True original label :\", class_id, class_names[class_id])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n",
            "True original label : 6 frog\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKd-ePD1HnuW"
      },
      "source": [
        "Zdefiniujmy ważne parametry i źródła danych."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKqT946e4hlK"
      },
      "source": [
        "no_of_classes = 10\n",
        "\n",
        "# You can try to standsardize images (using mean and std. dev.)\n",
        "standardize = True\n",
        "\n",
        "if standardize:\n",
        "    # per channel:\n",
        "    for i in range(3):\n",
        "        x_train_mean = np.mean(x_train[:,:,:,i])\n",
        "        x_train_std = np.std(x_train[:,:,:,i])\n",
        "        x_train[:,:,:,i] = (x_train[:,:,:,i] -x_train_mean) / x_train_std\n",
        "        x_test[:,:,:,i] = (x_test[:,:,:,i] -x_train_mean) /x_train_std\n",
        "\n",
        "    # per dataset:\n",
        "#     x_train_mean = np.mean(x_train)\n",
        "#     x_train_std = np.std(x_train)\n",
        "\n",
        "#     x_train = (x_train - x_train_mean)/x_train_std\n",
        "#     x_test = (x_test - x_train_mean)/x_train_std\n",
        "\n",
        "else:\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test / 255.0\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1ohboxmP2AO"
      },
      "source": [
        "Zdefiniujmy źródło danych z potokiem przetwarzania.\n",
        "\n",
        "\n",
        "Pamiętajmy również, że im większy rozmiar porcji danych (rozmiar danych i batch) tym więcej potrzebujemy pamięci."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj-_2rKD5M2g"
      },
      "source": [
        "# Preprocessing\n",
        "buffer_size = 1024\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "train_ds = (train_ds\n",
        "                  .shuffle(buffer_size=buffer_size)\n",
        "                  .batch(batch_size=batch_size, drop_remainder=True))\n",
        "\n",
        "valid_ds = (valid_ds\n",
        "                  .shuffle(buffer_size=buffer_size)\n",
        "                  .batch(batch_size=batch_size, drop_remainder=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Uyg7OtvSRi"
      },
      "source": [
        "Utwórzmy instancję prostego modelu i zapoznajmy się z wydrukiem warstw."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFiBqgmpMEzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9306ea5-4e3a-423a-c12d-15385db05be7"
      },
      "source": [
        "# Model to train\n",
        "input_shape = (image_height, image_width, image_components)\n",
        "model_to_train = get_Model(input_shape, no_of_classes)\n",
        "\n",
        "model_to_train.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"simple_res_net\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " residual_block_1 (Functiona  (None, 32, 32, 64)       74368     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_2 (Functiona  (None, 16, 16, 256)      757504    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 256)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 902,282\n",
            "Trainable params: 900,362\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvnneyUZBaEN"
      },
      "source": [
        "Przygotujmy również procedurę dynamicznej zmian współczynika szybkości uczenia (uwaga: poniższa procedura praktycznie nie wprowadzi żadnych zmian przy ustawieniu początkowej wartości współczynnika szybkości uczenia  na lr=0.001, co może być ważne dla \"adaptacyjnych\" algorytmów optymalizacyjnych, w których zgodnie z definicją współczynnik szybkości uczenia podlega adaptacyjnej zmianie.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auRtcSfWKHVn"
      },
      "source": [
        "# Remember, if you use the \"Adam\" optimizer or similar then learning rate can\n",
        "# automatically change between epochs: see the definition of the Adam opt.\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "\n",
        "  if epoch < 40:\n",
        "    eta = lr\n",
        "  else:\n",
        "    eta = lr * tf.math.exp(-0.01)\n",
        "\n",
        "  if eta < 0.001:\n",
        "    eta = 0.001\n",
        "\n",
        "  print(\"Learning rate is: \", eta)\n",
        "  return eta\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKtpQnBchQgN"
      },
      "source": [
        "Przygotujmy ustawienia procedury uczenia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkfsBmo0gYa8"
      },
      "source": [
        "def train_model(model, callbacks, opt, epochs=10, batch_size=32):\n",
        "  \"\"\"\n",
        "  Train model - use some global variable (you can modify the definition\n",
        "                to make this function more univeral)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  model.compile(\n",
        "    # Choose the optimizer\n",
        "    optimizer=opt,\n",
        "    # we use sparse version of the loss -> we do not need to use to_categorical()\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    # Introduce additional metric\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  model.fit(train_ds,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            # Use test data to perform validation\n",
        "            validation_data=valid_ds,\n",
        "            # Assign reference to the TB callback function\n",
        "            callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvOzwYonCaYa"
      },
      "source": [
        "Zdefiniujmy stosowne hiperparametry, wybierzmy algorytm optymalizacji, a następnie przeprowadźmy trening. Z góry zachęcam do przeprowadzenia wielu eksperymentów z różnymi ustawieniami modelu, algorytmu optymalizacyjnego oraz z zastosowaniem augmentacji danych (której dla prostoty przykładu nie stosujemy).\n",
        "\n",
        "Warto pobrać kopię notatnika i uruchomić go na innym (np. własnym) komputerze."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of25URSMQ1Fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba64ffe0-a2e4-4ecf-9956-c0dfadd5259a"
      },
      "source": [
        "# Use \"logs\" folder to for TB data\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# All callback functions\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "callbacks = [lr_scheduler, tensorboard_callback]\n",
        "\n",
        "# Redefine hiperparameters - e.g. use more epoch in the experiments\n",
        "# epochs = 200\n",
        "epochs = 20\n",
        "learning_rate = 0.01\n",
        "\n",
        "# You can try different optimalization algorithms\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=learning_rate*0.1, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "# Start training\n",
        "train_model(model_to_train, callbacks=callbacks, opt=sgd, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 1/20\n",
            "390/390 [==============================] - 48s 113ms/step - loss: 1.8286 - accuracy: 0.3300 - val_loss: 1.7008 - val_accuracy: 0.3886 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 2/20\n",
            "390/390 [==============================] - 44s 114ms/step - loss: 1.6288 - accuracy: 0.4110 - val_loss: 1.5731 - val_accuracy: 0.4428 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 3/20\n",
            "390/390 [==============================] - 44s 114ms/step - loss: 1.5359 - accuracy: 0.4505 - val_loss: 1.5036 - val_accuracy: 0.4629 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 4/20\n",
            "390/390 [==============================] - 44s 114ms/step - loss: 1.4712 - accuracy: 0.4770 - val_loss: 1.4461 - val_accuracy: 0.4813 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 5/20\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 1.4165 - accuracy: 0.4960 - val_loss: 1.4111 - val_accuracy: 0.4991 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 6/20\n",
            "390/390 [==============================] - 45s 114ms/step - loss: 1.3694 - accuracy: 0.5126 - val_loss: 1.3706 - val_accuracy: 0.5068 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 7/20\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 1.3276 - accuracy: 0.5279 - val_loss: 1.3317 - val_accuracy: 0.5237 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 8/20\n",
            "390/390 [==============================] - 45s 114ms/step - loss: 1.2899 - accuracy: 0.5409 - val_loss: 1.3387 - val_accuracy: 0.5244 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 9/20\n",
            "390/390 [==============================] - 45s 114ms/step - loss: 1.2567 - accuracy: 0.5519 - val_loss: 1.3250 - val_accuracy: 0.5254 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 10/20\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 1.2208 - accuracy: 0.5638 - val_loss: 1.2630 - val_accuracy: 0.5477 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 11/20\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 1.1957 - accuracy: 0.5746 - val_loss: 1.2938 - val_accuracy: 0.5416 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 12/20\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 1.1631 - accuracy: 0.5881 - val_loss: 1.2410 - val_accuracy: 0.5585 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 13/20\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 1.1323 - accuracy: 0.5982 - val_loss: 1.2789 - val_accuracy: 0.5465 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 14/20\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 1.1058 - accuracy: 0.6070 - val_loss: 1.2704 - val_accuracy: 0.5513 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 15/20\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 1.0766 - accuracy: 0.6184 - val_loss: 1.2459 - val_accuracy: 0.5608 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 16/20\n",
            "390/390 [==============================] - 47s 122ms/step - loss: 1.0514 - accuracy: 0.6256 - val_loss: 1.2335 - val_accuracy: 0.5645 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 17/20\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 1.0156 - accuracy: 0.6402 - val_loss: 1.2668 - val_accuracy: 0.5594 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 18/20\n",
            "390/390 [==============================] - 45s 114ms/step - loss: 0.9927 - accuracy: 0.6474 - val_loss: 1.2430 - val_accuracy: 0.5687 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 19/20\n",
            "390/390 [==============================] - 45s 115ms/step - loss: 0.9615 - accuracy: 0.6575 - val_loss: 1.2509 - val_accuracy: 0.5656 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 20/20\n",
            "390/390 [==============================] - 45s 114ms/step - loss: 0.9253 - accuracy: 0.6703 - val_loss: 1.2505 - val_accuracy: 0.5736 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72hVDoTzWjk7"
      },
      "source": [
        "Rozwińmy następnie nasz model zwiększając liczbę bloków rezydualnych do 8 (na wzór ResNet18: 1 warstwa splotowa na wejściu, 16 warstw spolotowych w 8 blokach [nie licząc warstw w połączeniach rezydualnych], 1 warstwa gęsta na końcu [nie licząc ostatniej warstwy gęstej z sotmax])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3hz9ZvoWq_4"
      },
      "source": [
        "def get_ResNet18(input_shape, no_of_classes):\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=7, padding='same')(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    #print(x.shape[1:])\n",
        "\n",
        "    x_in_1 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_1 = residual_block(x_in_1, 64, rescale=False, b_name='1')\n",
        "    x = base_model_1(x, training=True)\n",
        "\n",
        "    x_in_2 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_2 = residual_block(x_in_2, 64, rescale=False, b_name='2')\n",
        "    x = base_model_2(x, training=True)\n",
        "\n",
        "    x_in_3 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_3 = residual_block(x_in_3, 128, rescale=True, b_name='3')\n",
        "    x = base_model_3(x, training=True)\n",
        "\n",
        "    x_in_4 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_4 = residual_block(x_in_4, 128, rescale=False, b_name='4')\n",
        "    x = base_model_4(x, training=True)\n",
        "\n",
        "    x_in_5 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_5 = residual_block(x_in_5, 256, rescale=True, b_name='5')\n",
        "    x = base_model_5(x, training=True)\n",
        "\n",
        "    x_in_6 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_6 = residual_block(x_in_6, 256, rescale=False, b_name='6')\n",
        "    x = base_model_6(x, training=True)\n",
        "\n",
        "    x_in_7 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_7 = residual_block(x_in_7, 512, rescale=True, b_name='7')\n",
        "    x = base_model_7(x, training=True)\n",
        "\n",
        "    x_in_8 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_8 = residual_block(x_in_8, 512, rescale=False, b_name='8')\n",
        "    x = base_model_8(x, training=True)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x =  tf.keras.layers.Dense(1024)(x)\n",
        "    outputs = tf.keras.layers.Dense(no_of_classes, activation='softmax' )(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs, name='res_net_18_like')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di8zNgHbWsFv"
      },
      "source": [
        "Utwórzmy instancję prostego modelu i zapoznajmy się z wydrukiem warstw."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwvEz_uXW2mj",
        "outputId": "76a1e6f9-3779-4a3a-b230-770a4daa7d6c"
      },
      "source": [
        "input_shape = (image_height, image_width, image_components)\n",
        "model_to_train = get_ResNet18(input_shape, no_of_classes)\n",
        "\n",
        "model_to_train.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"res_net_18_like\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        9472      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " residual_block_1 (Functiona  (None, 32, 32, 64)       74368     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_2 (Functiona  (None, 32, 32, 64)       74368     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_3 (Functiona  (None, 16, 16, 128)      231296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_4 (Functiona  (None, 16, 16, 128)      296192    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_5 (Functiona  (None, 8, 8, 256)        921344    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_6 (Functiona  (None, 8, 8, 256)        1182208   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_7 (Functiona  (None, 4, 4, 512)        3677696   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_8 (Functiona  (None, 4, 4, 512)        4723712   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,726,474\n",
            "Trainable params: 11,716,874\n",
            "Non-trainable params: 9,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIe-pJdMW5gd"
      },
      "source": [
        "Przeprowadźmy trening (warto rozwinąć trening o więcej epok i np. augmentację dnych - zachęcam do eksperymentowania)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axW7vaPaXIVa",
        "outputId": "eaca36f5-280b-4ec3-e68e-a19e0edbdd78"
      },
      "source": [
        "# Use \"logs\" folder to for TB data\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# All callback functions\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "callbacks = [lr_scheduler, tensorboard_callback]\n",
        "\n",
        "# Redefine hiperparameters - e.g. use more epoch in the experiments\n",
        "# epochs = 200\n",
        "epochs = 20\n",
        "learning_rate = 0.01\n",
        "\n",
        "# You can try different optimalization algorithms\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=learning_rate*0.1, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "# Start training\n",
        "train_model(model_to_train, callbacks=callbacks, opt=sgd, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 1/20\n",
            "390/390 [==============================] - 106s 262ms/step - loss: 1.7644 - accuracy: 0.3665 - val_loss: 1.5518 - val_accuracy: 0.4421 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 2/20\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 1.4018 - accuracy: 0.5005 - val_loss: 1.3798 - val_accuracy: 0.5069 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 3/20\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 1.1820 - accuracy: 0.5815 - val_loss: 1.3491 - val_accuracy: 0.5272 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 4/20\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.9800 - accuracy: 0.6551 - val_loss: 1.3968 - val_accuracy: 0.5310 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 5/20\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.7905 - accuracy: 0.7221 - val_loss: 1.5585 - val_accuracy: 0.5291 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 6/20\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.6174 - accuracy: 0.7816 - val_loss: 1.7555 - val_accuracy: 0.5241 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 7/20\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.4902 - accuracy: 0.8257 - val_loss: 1.8921 - val_accuracy: 0.5272 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 8/20\n",
            "390/390 [==============================] - 101s 260ms/step - loss: 0.3945 - accuracy: 0.8605 - val_loss: 2.0509 - val_accuracy: 0.5161 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 9/20\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.3301 - accuracy: 0.8833 - val_loss: 2.2170 - val_accuracy: 0.5126 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 10/20\n",
            "390/390 [==============================] - 102s 260ms/step - loss: 0.2806 - accuracy: 0.9006 - val_loss: 2.2713 - val_accuracy: 0.5285 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 11/20\n",
            "390/390 [==============================] - 101s 260ms/step - loss: 0.2323 - accuracy: 0.9178 - val_loss: 2.3378 - val_accuracy: 0.5318 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 12/20\n",
            "390/390 [==============================] - 101s 260ms/step - loss: 0.1945 - accuracy: 0.9320 - val_loss: 2.4238 - val_accuracy: 0.5363 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 13/20\n",
            "390/390 [==============================] - 102s 260ms/step - loss: 0.1698 - accuracy: 0.9424 - val_loss: 2.4526 - val_accuracy: 0.5409 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 14/20\n",
            "390/390 [==============================] - 101s 260ms/step - loss: 0.1400 - accuracy: 0.9519 - val_loss: 2.6282 - val_accuracy: 0.5360 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 15/20\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.1215 - accuracy: 0.9569 - val_loss: 2.6985 - val_accuracy: 0.5498 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 16/20\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.1124 - accuracy: 0.9607 - val_loss: 2.7915 - val_accuracy: 0.5375 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 17/20\n",
            "390/390 [==============================] - 102s 260ms/step - loss: 0.1181 - accuracy: 0.9598 - val_loss: 2.8274 - val_accuracy: 0.5442 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 18/20\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.1061 - accuracy: 0.9625 - val_loss: 2.7859 - val_accuracy: 0.5467 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 19/20\n",
            "390/390 [==============================] - 102s 261ms/step - loss: 0.0925 - accuracy: 0.9676 - val_loss: 2.9027 - val_accuracy: 0.5432 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 20/20\n",
            "390/390 [==============================] - 101s 260ms/step - loss: 0.0842 - accuracy: 0.9708 - val_loss: 2.8956 - val_accuracy: 0.5497 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5m4wAOGXmp9"
      },
      "source": [
        "Uzyskane wyniki mogę nie być satysfakcjonujące dla danych walidacyjnych/testowych. Wprowadźmy dodatkowo augmentację danych demonstrując jak tworzenie modelu można podzielić na funkcjonalne części i z nich zestawić gotowy, nowy model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1Rqwr5YXnXN"
      },
      "source": [
        "img_height_dst = image_height * 2\n",
        "img_width_dst = image_width * 2\n",
        "img_depth_dst = 3\n",
        "\n",
        "input_shape_dst = (img_height_dst, img_width_dst, img_depth_dst)\n",
        "\n",
        "resize_layer = tf.keras.Sequential([\n",
        "  tf.keras.layers.Resizing(input_shape_dst[0], input_shape_dst[1]),\n",
        "])\n",
        "\n",
        "augmentation_layer = tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\", input_shape=input_shape_dst),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.RandomTranslation(height_factor=(-0.1, 0.1),width_factor=(-0.1, 0.1),fill_mode=\"constant\", fill_value=0.0),\n",
        "  ]\n",
        ")\n",
        "\n",
        "normalization_layer = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(1./255),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVrrmD64X5lS"
      },
      "source": [
        "Zdefiniujmy funkcję generacji modelu złożonego z innego modelu i zbioru warstw."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yn4idTXX8Zk"
      },
      "source": [
        "def get_Model_Augm(input_shape, no_of_classes=10):\n",
        "    # Building Model\n",
        "    prep_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "        resize_layer,\n",
        "        augmentation_layer,\n",
        "        # normalization_layer,\n",
        "        ])\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    x = prep_model(inputs)\n",
        "\n",
        "    # inputs = prep_model.output\n",
        "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=7, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    #print(x.shape[1:])\n",
        "\n",
        "    x_in_1 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_1 = residual_block(x_in_1, 64, rescale=False, b_name='1')\n",
        "    x = base_model_1(x, training=True)\n",
        "\n",
        "    x_in_2 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_2 = residual_block(x_in_2, 64, rescale=False, b_name='2')\n",
        "    x = base_model_2(x, training=True)\n",
        "\n",
        "    x_in_3 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_3 = residual_block(x_in_3, 128, rescale=True, b_name='3')\n",
        "    x = base_model_3(x, training=True)\n",
        "\n",
        "    x_in_4 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_4 = residual_block(x_in_4, 128, rescale=False, b_name='4')\n",
        "    x = base_model_4(x, training=True)\n",
        "\n",
        "    x_in_5 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_5 = residual_block(x_in_5, 256, rescale=True, b_name='5')\n",
        "    x = base_model_5(x, training=True)\n",
        "\n",
        "    x_in_6 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_6 = residual_block(x_in_6, 256, rescale=False, b_name='6')\n",
        "    x = base_model_6(x, training=True)\n",
        "\n",
        "    x_in_7 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_7 = residual_block(x_in_7, 512, rescale=True, b_name='7')\n",
        "    x = base_model_7(x, training=True)\n",
        "\n",
        "    x_in_8 = tf.keras.Input(shape=x.shape[1:])\n",
        "    base_model_8 = residual_block(x_in_8, 512, rescale=False, b_name='8')\n",
        "    x = base_model_8(x, training=True)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x =  tf.keras.layers.Dense(1024)(x)\n",
        "    outputs = tf.keras.layers.Dense(no_of_classes, activation='softmax' )(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs, name='res_net_augm')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmwdjQv5X-SC"
      },
      "source": [
        "Utwórzmy instancję prostego modelu i zapoznajmy się z wydrukiem warstw."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmFM6760YG8G",
        "outputId": "be67300b-e99a-438c-f9e7-ad83c3876d25"
      },
      "source": [
        "input_shape = (image_height, image_width, image_components)\n",
        "model_to_train = get_Model_Augm(input_shape, no_of_classes)\n",
        "\n",
        "model_to_train.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"res_net_augm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " sequential_3 (Sequential)   (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 64)        9472      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64, 64, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " residual_block_1 (Functiona  (None, 64, 64, 64)       74368     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_2 (Functiona  (None, 64, 64, 64)       74368     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_3 (Functiona  (None, 32, 32, 128)      231296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_4 (Functiona  (None, 32, 32, 128)      296192    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_5 (Functiona  (None, 16, 16, 256)      921344    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_6 (Functiona  (None, 16, 16, 256)      1182208   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_7 (Functiona  (None, 8, 8, 512)        3677696   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " residual_block_8 (Functiona  (None, 8, 8, 512)        4723712   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,726,474\n",
            "Trainable params: 11,716,874\n",
            "Non-trainable params: 9,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAk6So1lYKIO"
      },
      "source": [
        "Przeprowadźmy trening nowego modelu zawierającego operacje augmentacji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dil_Y_vPYRe7",
        "outputId": "aa8302e6-2908-4377-a24c-4bdad66334ff"
      },
      "source": [
        "# Use \"logs\" folder to for TB data\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# All callback functions\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "callbacks = [lr_scheduler, tensorboard_callback]\n",
        "\n",
        "# Redefine hiperparameters - e.g. use more epoch in the experiments\n",
        "# epochs = 200\n",
        "epochs = 20\n",
        "learning_rate = 0.01\n",
        "\n",
        "# You can try different optimalization algorithms\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=learning_rate*0.1, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "# Start training\n",
        "train_model(model_to_train, callbacks=callbacks, opt=sgd, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 1/20\n",
            "390/390 [==============================] - 330s 830ms/step - loss: 1.8278 - accuracy: 0.3378 - val_loss: 1.5806 - val_accuracy: 0.4312 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 2/20\n",
            "390/390 [==============================] - 322s 826ms/step - loss: 1.5657 - accuracy: 0.4361 - val_loss: 1.4015 - val_accuracy: 0.4948 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 3/20\n",
            "390/390 [==============================] - 323s 829ms/step - loss: 1.4644 - accuracy: 0.4742 - val_loss: 1.3118 - val_accuracy: 0.5378 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 4/20\n",
            "390/390 [==============================] - 323s 828ms/step - loss: 1.3903 - accuracy: 0.5008 - val_loss: 1.2446 - val_accuracy: 0.5557 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 5/20\n",
            "390/390 [==============================] - 321s 823ms/step - loss: 1.3348 - accuracy: 0.5235 - val_loss: 1.2122 - val_accuracy: 0.5640 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 6/20\n",
            "390/390 [==============================] - 321s 823ms/step - loss: 1.2794 - accuracy: 0.5424 - val_loss: 1.1520 - val_accuracy: 0.5890 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 7/20\n",
            "390/390 [==============================] - 321s 823ms/step - loss: 1.2353 - accuracy: 0.5608 - val_loss: 1.1218 - val_accuracy: 0.6055 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 8/20\n",
            "390/390 [==============================] - 321s 823ms/step - loss: 1.2007 - accuracy: 0.5759 - val_loss: 1.1014 - val_accuracy: 0.6155 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 9/20\n",
            "390/390 [==============================] - 322s 824ms/step - loss: 1.1591 - accuracy: 0.5895 - val_loss: 1.0785 - val_accuracy: 0.6223 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 10/20\n",
            "390/390 [==============================] - 323s 828ms/step - loss: 1.1276 - accuracy: 0.6003 - val_loss: 1.0629 - val_accuracy: 0.6227 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 11/20\n",
            "390/390 [==============================] - 323s 827ms/step - loss: 1.0982 - accuracy: 0.6102 - val_loss: 1.0109 - val_accuracy: 0.6458 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 12/20\n",
            "390/390 [==============================] - 323s 828ms/step - loss: 1.0713 - accuracy: 0.6224 - val_loss: 1.0084 - val_accuracy: 0.6466 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 13/20\n",
            "390/390 [==============================] - 323s 828ms/step - loss: 1.0470 - accuracy: 0.6299 - val_loss: 0.9753 - val_accuracy: 0.6535 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 14/20\n",
            "390/390 [==============================] - 323s 828ms/step - loss: 1.0211 - accuracy: 0.6402 - val_loss: 1.0201 - val_accuracy: 0.6462 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 15/20\n",
            "390/390 [==============================] - 323s 827ms/step - loss: 0.9992 - accuracy: 0.6502 - val_loss: 0.9335 - val_accuracy: 0.6691 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 16/20\n",
            "390/390 [==============================] - 322s 827ms/step - loss: 0.9769 - accuracy: 0.6554 - val_loss: 0.9344 - val_accuracy: 0.6720 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 17/20\n",
            "390/390 [==============================] - 324s 830ms/step - loss: 0.9617 - accuracy: 0.6603 - val_loss: 0.9159 - val_accuracy: 0.6800 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 18/20\n",
            "390/390 [==============================] - 324s 830ms/step - loss: 0.9369 - accuracy: 0.6696 - val_loss: 0.9216 - val_accuracy: 0.6772 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 19/20\n",
            "390/390 [==============================] - 324s 830ms/step - loss: 0.9182 - accuracy: 0.6773 - val_loss: 0.9043 - val_accuracy: 0.6842 - lr: 0.0100\n",
            "Learning rate is:  0.009999999776482582\n",
            "Epoch 20/20\n",
            "390/390 [==============================] - 324s 830ms/step - loss: 0.9030 - accuracy: 0.6829 - val_loss: 0.8846 - val_accuracy: 0.6934 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY5DXKQeYUyE"
      },
      "source": [
        "Na koniec zauważmy, że w TF są dostępne predefiniowane modele klasy ResNet. Poniżej pokazujemy przykładowych wydruk warstw dla dostępnego modelu ResNet50 z wskazaniem rozmiaru danych i liczby klas jak dla CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcqNdYo0YYku",
        "outputId": "70b3fba4-6c6c-40db-8c1a-a5c6754c13ad"
      },
      "source": [
        "model_to_train = tf.keras.applications.ResNet50(\n",
        "    include_top=True, weights=None, input_tensor=None,\n",
        "    input_shape=(image_height,image_width,image_components),\n",
        "    pooling=None, classes=no_of_classes,\n",
        "    classifier_activation='softmax'\n",
        ")\n",
        "\n",
        "model_to_train.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_23 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_23[0][0]']               \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                                                  'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
            "                                                                  'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
            "                                                                  'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
            "                                                                  'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
            "                                                                  'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
            "                                                                  'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " predictions (Dense)            (None, 10)           20490       ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 23,555,082\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk1Sl_dYYd_q"
      },
      "source": [
        "Proszę samodzielnie spróbować zastosować dostępny model ResNet50, budując na jego podstawie model obejmujący augmentację danych, większą liczbę epok i inne techniki tak, aby uzyskać jak najlepszy wynik klasyfikacji danych dla zbioru testowego."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj3UaPkQDggX"
      },
      "source": [
        "Zachęcam do eksperymentowania. Warto np. pobrać bazę ImageNet (https://image-net.org/download.php) i spróbować przeprowadzić trening modelu (Uwaga! Zbiór danych jest obszerny i proces uczenia może trwać bardzo długo - w zależności od dostępnej infrastruktury obliczeniowej). Można również poeksperymentować z wersjami ImageNet o pomniejszonych rozmiarach obrazów.\n",
        "\n",
        "Warto również dokonać eksperymentów z uwzględnieniem augmentacji danych."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIpYL7uTqUF5"
      },
      "source": [
        "<center>\n",
        "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n",
        "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
        "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n",
        "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
        "    </center>"
      ]
    }
  ]
}